<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Cold Doctor - Kevion's Blog</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Kevion's Blog</h1>
        <nav>
            <a href="index.html">Home</a> |
            <a href="about.html">About</a>
        </nav>
    </header>

    <main>
        <article>
            <h2>RE: "The Cold Doctor" (AI in Healthcare)</h2>
            <p class="date">February 9, 2026</p>

            <p>I read a post about AI doctors diagnosing cancer faster than humans, and I completely agree that for <em>diagnosis</em>, the machine is king. If I have a tumor, I want the AI to find it. I don't care about its bedside manner.</p>

            <p>But the point about the "loss of care" really resonated with me because we are seeing the exact same thing happen in sports medicine, and it's causing a weird psychological crisis for athletes.</p>

            <h3>The "Green Light" Problem</h3>

            <p>In the NFL right now, we use a system called the "Return to Play Protocol." It used to be a doctor moving your knee around and asking, "Does this hurt?"</p>

            <p>Now, it's a dashboard. The player runs on a force-plate treadmill. The AI analyzes their gait asymmetry. It checks their muscle firing rates. If the numbers are within 5% of the baseline, the screen turns Green. You are cleared to play.</p>

            <p>But here is the issue: The computer says the knee is fixed, but the <em>brain</em> doesn't believe it.</p>

            <p>I have a teammate who tore his ACL last year. The AI cleared him in 8 months. The data said he was stronger than before the injury. But every time he cut to the left, he hesitated. He was terrified.</p>

            <h3>The Machine Can't Measure Fear</h3>

            <p>The team doctors—who rely heavily on the dashboard—kept showing him the charts. "Look," they'd say, "The structural integrity is 100%. You are fine."</p>

            <p>But he wasn't fine. He was suffering from what psychologists call "kinesiophobia" (fear of movement). The AI couldn't measure his confidence. It couldn't measure the trauma of remembering the pop.</p>

            <p>Because the data said he was "healthy," the coaches pushed him hard. They thought he was "soft" because the machine said he was fixed. He ended up compensating, running weirdly to protect the "healthy" knee, and blew out his <em>other</em> hamstring a week later.</p>

            <h3>The Placebo (and Nocebo) Effect</h3>

            <p>A doctor's reassurance is part of the cure. I think that's scientifically true. If a human doctor looks you in the eye and says, "I've got you, you're strong, you're ready," your brain releases chemicals that actually help you perform.</p>

            <p>When a screen just flashes "READY," you don't get that biochemical boost.</p>

            <p>We are treating bodies like cars. If the mechanic says the engine is fixed, the car drives fine. But humans aren't cars. We have software (minds) that runs the hardware (bodies). AI is great at fixing the hardware, but it ignores the software completely.</p>

            <p>Until AI can learn to give a pep talk, I think we still need the human doctors.</p>

        </article>
    </main>

    <footer>
        <p>&copy; 2026 Kevion Milton</p>
    </footer>
</body>
</html>
